{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from tools.gpt_util import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T07:51:19.400401500Z",
     "start_time": "2024-02-20T07:51:18.793740700Z"
    }
   },
   "id": "d24a9ed746a25015"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "title = 'a survey on negative transfer'\n",
    "\n",
    "abs = '''\n",
    "Transfer learning (TL) utilizes data or knowledge from one or more source\n",
    "domains to facilitate the learning in a target domain. It is particularly\n",
    "useful when the target domain has very few or no labeled data, due to\n",
    "annotation expense, privacy concerns, etc. Unfortunately, the effectiveness of\n",
    "TL is not always guaranteed. Negative transfer (NT), i.e., leveraging source\n",
    "domain data/knowledge undesirably reduces the learning performance in the\n",
    "target domain, has been a long-standing and challenging problem in TL. Various\n",
    "approaches have been proposed in the literature to handle it. However, there\n",
    "does not exist a systematic survey on the formulation of NT, the factors\n",
    "leading to NT, and the algorithms that mitigate NT. This paper fills this gap,\n",
    "by first introducing the definition of NT and its factors, then reviewing about\n",
    "fifty representative approaches for overcoming NT, according to four\n",
    "categories: secure transfer, domain similarity estimation, distant transfer,\n",
    "and NT mitigation. NT in related fields, e.g., multi-task learning, lifelong\n",
    "learning, and adversarial attacks, are also discussed.\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T07:52:56.107784100Z",
     "start_time": "2024-02-20T07:52:56.084275200Z"
    }
   },
   "id": "ca3c5c971f3546b8"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['transfer learning']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_chatgpt_field(title,abs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T08:50:31.762068600Z",
     "start_time": "2023-12-21T08:50:29.830120500Z"
    }
   },
   "id": "71717bb673bbfff0"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['transfer learning', 'negative transfer', 'domain similarity']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_chatgpt_fields(title,abs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T08:50:37.693940100Z",
     "start_time": "2023-12-21T08:50:35.669614100Z"
    }
   },
   "id": "714c1ac50fb05e43"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def extract_keywords_from_article_with_gpt(text):\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"You are a profound researcher in the field of pattern recognition and machine intelligence. You are aware of all types of keywords, such as keyword, index terms, etc.Please note: The text is extracted from the PDF, so line breaks may appear anywhere, or even footnotes may appear between consecutive lines of text.\"},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": f'''I will give you the text in the first page of an academic paper, you should read it carefully. If there is no provided keywords, ask with None. If there does exist author provided keywords, answer with the extracted keywords (only keywords) in the following format: keyword1,keyword2,...,keywordN. You should answer only with the keyword, do not answer with words like 'index terms'\n",
    "         The text of the first page:{text}\n",
    "    '''},\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        # prompt需要用英语替换，少占用token。\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    result = ''\n",
    "    print(response)\n",
    "    for choice in response.choices:\n",
    "        result += choice.message.content\n",
    "    result = [i.strip() for i in result.split(',')]\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T12:41:16.132145600Z",
     "start_time": "2023-12-22T12:41:16.119021500Z"
    }
   },
   "id": "b313cd78eda1a201"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3214/3214 [09:59<00:00,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6325865797670557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from database.DBEntity import PaperMapping\n",
    "from furnace.arxiv_paper import Arxiv_paper\n",
    "\n",
    "from sqlalchemy import create_engine, Column, Integer, String\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "from furnace.arxiv_paper import Arxiv_paper\n",
    "from furnace.google_scholar_paper import Google_paper\n",
    "from tools.gpt_util import *\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "def remove_keywords(text, keywords):\n",
    "    for keyword in keywords:\n",
    "        text = text.replace(keyword, \"\")\n",
    "    return text\n",
    "\n",
    "# 创建数据库引擎\n",
    "engine = create_engine('mysql+mysqlconnector://root:xxxx@localhost/ripami')\n",
    "\n",
    "# 创建数据库表\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "# 创建会话\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "results = session.query(PaperMapping).all()\n",
    "i = 0\n",
    "total_edit_dist = 0.0\n",
    "remove_kwds = ['deep learning','machine learning','survey','literature review','review','review paper','survey paper','taxonomy','computer vision','nlp','cv','natural language processing','computer science','AI','artificial intelligence']\n",
    "import Levenshtein\n",
    "for row in tqdm(results):\n",
    "    if row.keywords and row.keywords != 'None':\n",
    "        if 'deep learning' not in row.keywords.lower():\n",
    "            if row.publication_date>datetime(year=2021,month=10,day=7):\n",
    "                if row.idLiterature.endswith('9') or row.idLiterature.endswith('7') or row.idLiterature.endswith('2') or row.idLiterature.endswith('6'): # random select papers\n",
    "                    print(row.title,row.gpt_keyword)\n",
    "                    pred_kwd_seq = ' '.join(get_chatgpt_fields(row.title,row.abstract,True)).lower()\n",
    "                    GT_kwd_seq = ' '.join(row.keywords.split(';')).lower()\n",
    "                    # print(pred_kwd_seq)\n",
    "                    # print(GT_kwd_seq)\n",
    "                    if max(len(pred_kwd_seq), len(GT_kwd_seq)) == 0:\n",
    "                        continue\n",
    "                    # print(GT_kwd_seq)\n",
    "                    GT_kwd_seq = remove_keywords(GT_kwd_seq, remove_kwds)\n",
    "                    # print(GT_kwd_seq)\n",
    "                    total_edit_dist+=(Levenshtein.distance(pred_kwd_seq, GT_kwd_seq)/ max(len(pred_kwd_seq), len(GT_kwd_seq)))\n",
    "                    i+=1\n",
    "print(total_edit_dist/i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T12:01:50.713884100Z",
     "start_time": "2023-12-28T11:51:50.500373400Z"
    }
   },
   "id": "77d05cc6727e666d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "写入CSV"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0af45fa5e140a67"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3532/3532 [00:00<00:00, 504625.19it/s]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from database.DBEntity import PaperMapping\n",
    "from furnace.arxiv_paper import Arxiv_paper\n",
    "\n",
    "from sqlalchemy import create_engine, Column, Integer, String\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "from furnace.arxiv_paper import Arxiv_paper\n",
    "from furnace.google_scholar_paper import Google_paper\n",
    "from tools.gpt_util import *\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "def remove_keywords(text, keywords):\n",
    "    for keyword in keywords:\n",
    "        text = text.replace(keyword, \"\")\n",
    "    return text\n",
    "\n",
    "# 创建数据库引擎\n",
    "engine = create_engine('mysql+mysqlconnector://root:xxxx@localhost/ripami')\n",
    "\n",
    "# 创建数据库表\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "# 创建会话\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "results = session.query(PaperMapping).all()\n",
    "i = 0\n",
    "total_edit_dist = 0.0\n",
    "import Levenshtein\n",
    "with open('gpt_keyword.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for row in tqdm(results):\n",
    "        if row.publication_date>datetime(year=2021,month=10,day=7):\n",
    "            if row.idLiterature.endswith('9') or row.idLiterature.endswith('7') or row.idLiterature.endswith('2') or row.idLiterature.endswith('6'): # random select papers\n",
    "                writer.writerow([row.title,row.gpt_keyword])\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:45:33.369944700Z",
     "start_time": "2024-01-10T01:45:31.778859500Z"
    }
   },
   "id": "566e73811ecbe58e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multiple Prompts Tests"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d793c2d3f2e8ceb6"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello world', 'This is a test', 'Hello there']\n"
     ]
    }
   ],
   "source": [
    "def remove_keywords(text_list, keywords):\n",
    "    result_list = []\n",
    "    for text in text_list:\n",
    "        if text not in keywords:\n",
    "            result_list.append(text)\n",
    "    return result_list\n",
    "text_list = [\"Hello world\", \"This is a test\", \"Python programming\", \"Hello there\"]\n",
    "keywords = [\"Hello\", \"Python programming\"]\n",
    "\n",
    "result = remove_keywords(text_list, keywords)\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T11:13:56.474524500Z",
     "start_time": "2024-01-03T11:13:56.463015500Z"
    }
   },
   "id": "6d3943a7264eda9a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prompts Comparison Examples"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3298c78bd5b9bf6b"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Diffusion Models in NLP: A Survey ['Diffusion Models']\n",
      "Diffusion Models in NLP: A Survey ['NLP']\n",
      "------------------------------\n",
      "-\n",
      "Fine-grained Image Analysis with Deep Learning: A Survey ['Fine-grained Image Analysis']\n",
      "Fine-grained Image Analysis with Deep Learning: A Survey ['Image Analysis']\n",
      "------------------------------\n",
      "-\n",
      "Object Detection with Deep Learning: A Review ['Object Detection']\n",
      "Object Detection with Deep Learning: A Review ['Object Detection']\n",
      "------------------------------\n",
      "-\n",
      "A Review of Object Detection Based on Deep Learning ['Object Detection']\n",
      "A Review of Object Detection Based on Deep Learning ['Object detection']\n",
      "------------------------------\n",
      "-\n",
      "Recent Advances in Deep Learning for Object Detection ['Deep Learning', 'Object Detection']\n",
      "Recent Advances in Deep Learning for Object Detection ['Recent Advances']\n",
      "------------------------------\n",
      "-\n",
      "Deep Learning for Object Detection: A Survey ['Object Detection']\n",
      "Deep Learning for Object Detection: A Survey ['Object Detection']\n",
      "------------------------------\n",
      "-\n",
      "Recent progresses on object detection: a brief review ['object detection']\n",
      "Recent progresses on object detection: a brief review ['object detection']\n",
      "------------------------------\n",
      "-\n",
      "A Survey of Modern Deep Learning Based Object Detection Models ['Object Detection']\n",
      "A Survey of Modern Deep Learning Based Object Detection Models ['object detection']\n",
      "------------------------------\n",
      "-\n",
      "A Review of Research on Object Detection Based on Deep Learning ['Target detection']\n",
      "A Review of Research on Object Detection Based on Deep Learning ['object detection']\n",
      "------------------------------\n",
      "-\n",
      "Automatic Text Summarization: A Comprehensive Survey ['Text Summarization']\n",
      "Automatic Text Summarization: A Comprehensive Survey ['text summarization']\n",
      "------------------------------\n",
      "-\n",
      "A Survey of Automatic Text Summarization: Progress, Process and Challenges ['Automatic Text Summarization']\n",
      "A Survey of Automatic Text Summarization: Progress, Process and Challenges ['text summarization']\n",
      "------------------------------\n",
      "-\n",
      "Review of Automatic Text Summarization Techniques & Methods ['Automatic Text Summarization']\n",
      "Review of Automatic Text Summarization Techniques & Methods ['text summarization']\n",
      "------------------------------\n",
      "-\n",
      "Deep Reinforcement and Transfer Learning for Abstractive Text Summarization: A Review ['Abstractive Text Summarization']\n",
      "Deep Reinforcement and Transfer Learning for Abstractive Text Summarization: A Review ['text summarization']\n",
      "------------------------------\n",
      "-\n",
      "Exploring the Landscape of Automatic Text Summarization: A Comprehensive Survey ['Automatic Text Summarization']\n",
      "Exploring the Landscape of Automatic Text Summarization: A Comprehensive Survey ['text summarization']\n",
      "------------------------------\n",
      "-\n",
      "Automatic Text Summarization Methods: A Comprehensive Review ['Automatic Text Summarization']\n",
      "Automatic Text Summarization Methods: A Comprehensive Review ['text summarization']\n",
      "------------------------------\n",
      "-\n",
      "Self-supervised Learning of Graph Neural Networks: A Unified Review ['Self-supervised Learning']\n",
      "Self-supervised Learning of Graph Neural Networks: A Unified Review ['Graph Neural Networks']\n",
      "------------------------------\n",
      "-\n",
      "Graph Self-supervised Learning: A Survey ['Graph self-supervised learning']\n",
      "Graph Self-supervised Learning: A Survey ['graph self-supervised learning']\n",
      "------------------------------\n",
      "-\n",
      "Self-supervised Learning on Graphs: Contrastive, Generative, or Predictive ['Graph self-supervised learning']\n",
      "Self-supervised Learning on Graphs: Contrastive, Generative, or Predictive ['self-supervised learning on graphs']\n",
      "------------------------------\n",
      "-\n",
      "Automated Self-supervised Learning for Graphs ['Graph self-supervised learning.']\n",
      "Automated Self-supervised Learning for Graphs ['graph learning']\n",
      "------------------------------\n",
      "-\n",
      "Medical Image Segmentation Using Deep Learning: A Survey ['Medical Image Segmentation']\n",
      "Medical Image Segmentation Using Deep Learning: A Survey ['medical image segmentation']\n",
      "------------------------------\n",
      "-\n",
      "Deep Neural Networks for Medical Image Segmentation ['Medical Image Segmentation']\n",
      "Deep Neural Networks for Medical Image Segmentation ['medical image segmentation']\n",
      "------------------------------\n",
      "-\n",
      "Medical Image Segmentation Using Deep Semantic-based Methods: A Review of Techniques, Applications, and Emerging Trends ['Medical Image Segmentation']\n",
      "Medical Image Segmentation Using Deep Semantic-based Methods: A Review of Techniques, Applications, and Emerging Trends ['medical image segmentation']\n",
      "------------------------------\n",
      "-\n",
      "A Review of Deep-learning-based Medical Image Segmentation Methods ['Medical Image Segmentation']\n",
      "A Review of Deep-learning-based Medical Image Segmentation Methods ['medical image segmentation']\n",
      "------------------------------\n",
      "-\n",
      "Medical Image Segmentation on GPUs - A Comprehensive Review ['Medical Image Segmentation']\n",
      "Medical Image Segmentation on GPUs - A Comprehensive Review ['medical image segmentation']\n",
      "------------------------------\n",
      "-\n",
      "Visual Question Answering Using Deep Learning: A Survey and Performance Analysis ['Visual Question Answering']\n",
      "Visual Question Answering Using Deep Learning: A Survey and Performance Analysis ['visual question answering']\n",
      "------------------------------\n",
      "-\n",
      "A Survey of Methods, Datasets, and Evaluation Metrics for Visual Question Answering ['Visual Question Answering']\n",
      "A Survey of Methods, Datasets, and Evaluation Metrics for Visual Question Answering ['visual question answering']\n",
      "------------------------------\n",
      "-\n",
      "Biomedical Question Answering: A Survey of Approaches and Challenges ['Biomedical Question Answering']\n",
      "Biomedical Question Answering: A Survey of Approaches and Challenges ['biomedical answering']\n",
      "------------------------------\n",
      "-\n",
      "A Review on Medical Textual Question Answering Systems Based on Deep Learning Approaches ['Medical Textual Question Answering Systems']\n",
      "A Review on Medical Textual Question Answering Systems Based on Deep Learning Approaches ['question answering']\n",
      "------------------------------\n",
      "-\n",
      "A Survey on Vision Transformer ['Vision Transformer']\n",
      "A Survey on Vision Transformer ['Vision']\n",
      "------------------------------\n",
      "-\n",
      "Transformers in Vision: A Survey ['Transformer Models']\n",
      "Transformers in Vision: A Survey ['transformers']\n",
      "------------------------------\n",
      "-\n",
      "A Survey of Visual Transformers ['Visual Transformers']\n",
      "A Survey of Visual Transformers ['Transformers']\n",
      "------------------------------\n",
      "-\n",
      "A Survey on Large Language Model Based Autonomous Agents ['Large Language Model Based Autonomous Agents']\n",
      "A Survey on Large Language Model Based Autonomous Agents ['Language Model']\n",
      "------------------------------\n",
      "-\n",
      "The Rise and Potential of Large Language Model Based Agents: A Survey ['Large Language Model Based Agents']\n",
      "The Rise and Potential of Large Language Model Based Agents: A Survey ['language models']\n",
      "------------------------------\n",
      "-\n",
      "A Comprehensive Review on Sentiment Analysis: Tasks, Approaches and Applications ['Sentiment Analysis']\n",
      "A Comprehensive Review on Sentiment Analysis: Tasks, Approaches and Applications ['sentiment']\n",
      "------------------------------\n",
      "-\n",
      "A Systematic Review of Aspect-based Sentiment Analysis (ABSA): Domains, Methods, and Trends ['Aspect-based Sentiment Analysis']\n",
      "A Systematic Review of Aspect-based Sentiment Analysis (ABSA): Domains, Methods, and Trends ['Sentiment Analysis']\n",
      "------------------------------\n",
      "-\n",
      "A Survey of Diffusion Models in Natural Language Processing ['Diffusion Models']\n",
      "A Survey of Diffusion Models in Natural Language Processing ['Diffusion']\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from retry import retry\n",
    "@retry(delay=6,)\n",
    "def get_chatgpt_field_from_title_1(title, extra_prompt=True):\n",
    "    sys_content = \"Examine the survey paper's title and extract the core research subject. Use your language processing capabilities to identify key themes of focus within academic titles.\"\n",
    "    usr_prompt = (f\"Please analyze the title of this survey paper and determine the main subject it investigates. For example, for the title 'A Survey of Self-Supervised and Few-Shot Object Detection', identify the key research area, which in this case is 'object detection'. Avoid broad or general terms such as 'deep learning', 'computer vision', or 'surveys'. Instead, your interpretation should focus on extracting the main investigated area from the paper's title. Answer with the word only in the following format: xxx\"\n",
    "                  f\"Paper Title: {title}\")\n",
    "    if extra_prompt:\n",
    "        messages = [\n",
    "            {\"role\": \"system\",\n",
    "             \"content\": sys_content},\n",
    "\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f'''{usr_prompt}\n",
    "                        Given Title: A Survey of Self-Supervised and Few-Shot Object Detection\n",
    "                        '''},\n",
    "            {\"role\": \"assistant\",\n",
    "             \"content\": 'objection detection'},\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f'''{usr_prompt}\n",
    "                                    Given Title: {title}\n",
    "                                '''},\n",
    "        ]\n",
    "    else:\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\",\n",
    "             \"content\": sys_content},\n",
    "\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f'''{usr_prompt}\n",
    "                Given Title: {title}\n",
    "            '''},\n",
    "        ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        # prompt需要用英语替换，少占用token。\n",
    "        messages=messages,\n",
    "    )\n",
    "    result = ''\n",
    "    for choice in response.choices:\n",
    "        result += choice.message.content\n",
    "    result = result.split(',')\n",
    "    result = [i.strip() for i in result]\n",
    "    return result\n",
    "    # usr_prompt = (\"Hello ChatGPT, I have a task that involves determining the main subject of a review paper based on its title and abstract. Here's how you can assist me:\"\n",
    "    #               \"1 Read Carefully: Begin by reading the title and abstract of the paper thoroughly.\"\n",
    "    #                \"2 Identify Key Terms: Look for key terms or phrases in the title and abstract that are repeated or emphasized. These often indicate the primary focus of the paper.\"\n",
    "    # \n",
    "    #                 \"3 Discern the Field: Determine the field or subject area the paper belongs to, such as 'object detection' 'vision transformer' or 'Economics.'\"\n",
    "    # \n",
    "    #                 \"4 Avoid Details: Focus on the general topic rather than specific methods, tools, or case studies mentioned. But also avoid using too broad or overly general term like 'deep learning', 'taxonomy', or 'surveys' \"\n",
    "    #                 \n",
    "    #                 \"5 Summarize: Provide a concise summary of your findings, stating clearly what you believe is the main topic of the review paper. \"\n",
    "    #                 \" You MUST answer with the word only in the following format: xxx\"\n",
    "    # \n",
    "    #                 \"Example: If the paper is titled 'A Comprehensive Analysis of Neural Network Approaches in Image Recognition' your response should identify 'Image Recognition' as the main topic.\"\n",
    "    #                 f\"Please apply this approach to the following title and abstract: Title: {title}    Abstract: {abstract}\"\n",
    "    #               )\n",
    "@retry(delay=6,)\n",
    "def get_chatgpt_field_1(title, abstract, extra_prompt=False):\n",
    "    sys_content = (\"You are a profound researcher who is good at identifying the topic key phrase from paper's title and \"\n",
    "                   \"abstract. The key phrase is going to be used to retrieve related paper from online scholar search engines.\")\n",
    "    usr_prompt = (\" I have a task that involves determining the main subject of a review paper based on its title and abstract. Here's how you can assist me:\"\n",
    "                  \n",
    "                  \"1 Read Carefully: Begin by reading the title and abstract of the paper thoroughly.\"\n",
    "                  \n",
    "                   \"2 Identify Key Terms: Look for key term or phrase in the title and abstract that are repeated or emphasized. These often indicate the primary focus of the paper.\"\n",
    "\n",
    "                    \"3 Discern the Field: Determine the field or subject area the paper belongs to, such as 'object detection' 'vision transformer' or 'character recognition'\"\n",
    "\n",
    "                    \"4 Avoid too broad or detailed: Focus on the general topic or technique adopted in a certain field. Avoid using too broad or overly general term like 'deep learning', 'computer vision', 'NLP', or 'surveys', unless the investigate field of research is really that broad.\"\n",
    "                    \n",
    "                    \"5 Summarize: State clearly what you believe is the main topic of the review paper. \"\n",
    "                    \n",
    "                    \"Example: If the paper is titled 'Deep Learning-Based Diffusion Models in NLP: A Comprehensive Survey of Approaches and Challenges' your response should be 'Diffusion Models' as the key phrase.\"\n",
    "                    f\"Please apply this approach to the following title and abstract: Title: {title}    Abstract: {abstract}\" \n",
    "                  \n",
    "                    \"Remember You MUST answer with key word ONLY in the following format: : xxx \"\n",
    "                  \" DO NOT REPLY WITH ANY OTHER WORDS\"\n",
    "                  )\n",
    "    print('-')\n",
    "    if extra_prompt:\n",
    "        messages = [\n",
    "            {\"role\": \"system\",\n",
    "             \"content\": sys_content},\n",
    "\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f'''{usr_prompt}\n",
    "                        Given Title: A Survey of Self-Supervised and Few-Shot Object Detection\n",
    "                        Given Abstract: Labeling data is often expensive and time-consuming, especially for tasks such as object detection and instance segmentation, which require dense labeling of the image. While few-shot object detection is about training a model on novel(unseen) object classeswith little data, it still requires prior training onmany labeled examples of base(seen) classes. On the other hand, self-supervisedmethods aimat learning representations fromunlabeled data which transfer well to downstream tasks such as object detection. Combining few-shot and self-supervised object detection is a promising research direction. In this survey, we reviewand characterize themost recent approaches on few-shot and self-supervised object detection. Then, we give our main takeaways and discuss future research directions. Project page: https://gabrielhuang.github.io/fsod-survey/\n",
    "                    '''},\n",
    "            {\"role\": \"assistant\",\n",
    "             \"content\": 'objection detection'},\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f'''{usr_prompt}\n",
    "                                    Given Title: {title}\n",
    "                                    Given Abstract: {abstract}\n",
    "                                '''},\n",
    "        ]\n",
    "    else:\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\",\n",
    "             \"content\": sys_content},\n",
    "\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f'''{usr_prompt}\n",
    "                Given Title: {title}\n",
    "                Given Abstract: {abstract}\n",
    "            '''},\n",
    "        ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        # prompt需要用英语替换，少占用token。\n",
    "        messages=messages,\n",
    "    )\n",
    "    result = ''\n",
    "    for choice in response.choices:\n",
    "        result += choice.message.content\n",
    "    result = result.split(',')\n",
    "    result = [i.strip() for i in result]\n",
    "    return result\n",
    "titles = [\n",
    "    'Diffusion Models in NLP: A Survey',\n",
    "    \"Fine-grained Image Analysis with Deep Learning: A Survey\",\n",
    "    \"Object Detection with Deep Learning: A Review\",\n",
    "    \"A Review of Object Detection Based on Deep Learning\",\n",
    "    \"Recent Advances in Deep Learning for Object Detection\",\n",
    "    \"Deep Learning for Object Detection: A Survey\",\n",
    "    \"Recent progresses on object detection: a brief review\",\n",
    "    \"A Survey of Modern Deep Learning Based Object Detection Models\",\n",
    "    \"A Review of Research on Object Detection Based on Deep Learning\",\n",
    "    \"Automatic Text Summarization: A Comprehensive Survey\",\n",
    "    \"A Survey of Automatic Text Summarization: Progress, Process and Challenges\",\n",
    "    \"Review of Automatic Text Summarization Techniques & Methods\",\n",
    "    \"Deep Reinforcement and Transfer Learning for Abstractive Text Summarization: A Review\",\n",
    "    \"Exploring the Landscape of Automatic Text Summarization: A Comprehensive Survey\",\n",
    "    \"Automatic Text Summarization Methods: A Comprehensive Review\",\n",
    "    \"Self-supervised Learning of Graph Neural Networks: A Unified Review\",\n",
    "    \"Graph Self-supervised Learning: A Survey\",\n",
    "    \"Self-supervised Learning on Graphs: Contrastive, Generative, or Predictive\",\n",
    "    \"Automated Self-supervised Learning for Graphs\",\n",
    "    \"Medical Image Segmentation Using Deep Learning: A Survey\",\n",
    "    \"Deep Neural Networks for Medical Image Segmentation\",\n",
    "    \"Medical Image Segmentation Using Deep Semantic-based Methods: A Review of Techniques, Applications, and Emerging Trends\",\n",
    "    \"A Review of Deep-learning-based Medical Image Segmentation Methods\",\n",
    "    \"Medical Image Segmentation on GPUs - A Comprehensive Review\",\n",
    "    \"Visual Question Answering Using Deep Learning: A Survey and Performance Analysis\",\n",
    "    \"A Survey of Methods, Datasets, and Evaluation Metrics for Visual Question Answering\",\n",
    "    \"Biomedical Question Answering: A Survey of Approaches and Challenges\",\n",
    "    \"A Review on Medical Textual Question Answering Systems Based on Deep Learning Approaches\",\n",
    "    \"A Survey on Vision Transformer\",\n",
    "    \"Transformers in Vision: A Survey\",\n",
    "    \"A Survey of Visual Transformers\",\n",
    "    \"A Survey on Large Language Model Based Autonomous Agents\",\n",
    "    \"The Rise and Potential of Large Language Model Based Agents: A Survey\",\n",
    "    'A Comprehensive Review on Sentiment Analysis: Tasks, Approaches and Applications',\n",
    "    'A Systematic Review of Aspect-based Sentiment Analysis (ABSA): Domains, Methods, and Trends','A Survey of Diffusion Models in Natural Language Processing',\n",
    "]\n",
    "from furnace.semantic_scholar_paper import *\n",
    "for t in titles:\n",
    "    s2paper = S2paper(t)\n",
    "    print(t,get_chatgpt_field_1(t,s2paper.abstract))\n",
    "    print(t,get_chatgpt_field_from_title_1(t))\n",
    "    print('------------------------------')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T13:14:57.662350600Z",
     "start_time": "2024-01-09T13:12:14.212216100Z"
    }
   },
   "id": "2ec6e416f578f3c8"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surround-view fisheye camera perception for automated driving: overview, survey & challenges\n",
      "robust multi-view representation: a unified perspective from multi-view learning to domain adaption\n",
      "fusion of microgrid control with model-free reinforcement learning: review and vision\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "def read_and_write_csv(input_file, output_file):\n",
    "    with open(input_file, 'r', newline='',encoding='gbk',) as input_csvfile, \\\n",
    "            open(output_file, 'w', newline='',encoding='gbk',) as output_csvfile:\n",
    "        reader = csv.reader(input_csvfile)\n",
    "        writer = csv.writer(output_csvfile)\n",
    "        \n",
    "        for row in reader:\n",
    "            try:\n",
    "                if S2paper(row[0]).abstract:\n",
    "                    processed_row = [row[0],S2paper(row[0]).abstract,row[1]]\n",
    "                    writer.writerow(processed_row)  # 写入处理后的行数据\n",
    "                else:\n",
    "                    continue\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "\n",
    "# 示例调用\n",
    "read_and_write_csv('gpt_keyword_GT.csv','gpt_keyword_GT_abs.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T06:55:54.702771300Z",
     "start_time": "2024-01-10T06:55:37.720255400Z"
    }
   },
   "id": "d37851a53d36b1a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GPT Keyword Test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6154b429546d776"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [04:35,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying the topic of the paper based on the given title and abstract. So that I can use it as keyword to search highly related papers from Semantic Scholar.  Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on keyword that are unique and directly pertinent to the paper's subject. Answer with the word only in the following format: xxx 0.3279365984661752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [03:21,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying the key phrase of the paper based on the given title and abstract. So that I can use it as keyword to search highly related papers from Google Scholar.  Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on keyword that are unique and directly pertinent to the paper's subject. Answer with the key phrase only in the following format: xxx 0.4100033166159081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [03:39,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying the topic of the paper based on the given title and abstract. So that I can use it as keyword to search highly related papers from Google Scholar.  Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on keyword that are unique and directly pertinent to the paper's subject. Emphasize any particular subfields or methodologies the paper might be concentrating on.  Answer with the word only in the following format: xxx 0.2979762116344853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [03:44,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need you strictly follow the instruct: 1. Identifying the topic of the paper based on the given title and abstract. So that I can use it as keyword to search highly related papers from Google Scholar.  2. Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. 3. Instead, focus on keyword that are unique and directly pertinent to the paper's subject. 4. Answer with the word only in the following format: xxx 0.2872543602042803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [03:09,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying the topic of the paper based on the given title and abstract. I'm going to write a review of the same topic and I will directly use it as keyword to retrieve enough related reference papers in the same topic from scholar search engine.  Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on keyword that are unique and directly pertinent to the paper's subject. Answer with the word only in the following format: xxx 0.28395122417586455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [03:18,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying the topic of the paper based on the given title and abstract. So that I can use it as keyword to search highly related papers from Google Scholar.  Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on keyword that are unique and directly related to the paper's subject. Answer with the word only in the following format: xxx 0.32154902286953246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [02:57,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying the topic of the paper based on the given title and abstract. So that I can use it as keyword to search highly related papers from Google Scholar.  Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Answer with the word only in the following format: xxx 0.29990839992367824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [03:08,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying the topic of the paper based on the given title and abstract. Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on keyword that are unique and directly pertinent to the paper's subject. Answer with the word only in the following format: xxx 0.3634402706042023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import tempfile\n",
    "import shutil\n",
    "from retry import retry\n",
    "import Levenshtein\n",
    "from tqdm import tqdm\n",
    "from furnace.semantic_scholar_paper import *\n",
    "def normalized_edit_distance(str1, str2):\n",
    "    edit_distance = Levenshtein.distance(str1, str2)\n",
    "    max_length = max(len(str1), len(str2))\n",
    "    normalized_distance = edit_distance / max_length\n",
    "    return normalized_distance\n",
    "usr_prompts = [\n",
    "               \"Given title and abstract, please provide the seaching key phrase for me so that I can use it as keyword to search highly related papers from Google Scholar or Semantic Scholar. Please avoid responding with overly general keywords such as deep learning, taxonomy, or surveys, etc. Answer with the words only in the following format: xxx\",\n",
    "    \n",
    "               \"Based on the provided title and abstract of a literature review, identify the area keyword that the review investigate. The area keyword should be enough to retrieve related literature on Google Scholar.  You need to avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on keyword that are representative to various subjects of the paper. The output should be formatted as following: xxx\",\n",
    "\n",
    "                \"I want you 1.Read the given title and abstract of a review. 2.Identify the main topic that the review investigated. 3. Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. 4. You should summary only 1 key phrase. Answer with the key phrase only and the output should be formatted as following: xxx\",\n",
    "    \n",
    "                \"Read the provided title and the abstract. Based on the main focus and content of the paper, identify the single most important keyword that represents the core theme of the research. Consider the main technology, application, and objective discussed in the paper to determine this keyword.You need to avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on keyword that are representative to various subjects of the paper. The output should be formatted as following: xxx\",\n",
    "    \n",
    "                \"Based on the given title and abstract, identify one keyword that best represents the main theme or research area of this paper. This keyword should succinctly encapsulate the core focus of the article and be closely related to the research direction presented. The output should be formatted as following: xxx\",\n",
    "    \n",
    "                \"Identifying the topic of the paper based on the given title and abstract. So that I can use it as \"\n",
    "                                  \"keyword to search highly related papers from Google Scholar.  Avoid using broad or overly general \"\n",
    "                                  \"term like 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on keyword that are unique \"\n",
    "                                  \"and directly pertinent to the paper's subject.Answer with the word only in the\"\n",
    "                                  \"following format: xxx\",\n",
    "                'Please analyze the title and abstract provided below and identify the main topic or central theme of the review paper. Focus on key terms and the overall subject matter to determine the primary area of research or discussion.The output should be formatted as following: xxx',\n",
    "    \n",
    "                    \"Please analyze the title and abstract of the provided paper to identify its specific topic. Use this analysis to determine precise, unique keyword that are directly relevant to the paper's content. These keyword will be used for searching related academic papers on Google Scholar. Avoid generic or broad terms such as 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on distinctive keywords that encapsulate the essence of the paper's topic. Please respond with the identified keyword only, formatted as follows: keyword\",\n",
    "    \n",
    "                'Task: Please read the title and abstract provided below. Based on your understanding, identify the single most central topic key phrase that captures the core theme or subject of this review paper. This key phrase should be a concise representation of the main focus of the paper. Answer with the keywords only and the output should be formatted as following: xxx ',\n",
    "\n",
    "\n",
    "              ]\n",
    "PE_prompt = [\"Task: Please read the title and abstract provided below. Based on your understanding, identify the single most central topic key phrase that captures the core theme or subject of this review paper. This key phrase should be a concise representation of the main focus of the paper. Answer with the keywords only and the output should be formatted as following: xxx\",\n",
    "                \"1.\tTask Overview: ChatGPT, your task is to identify a single key topic phrase from the provided title and abstract of a review paper. \"\n",
    "                \"2.\tClear Instruction: Extract only one key topic phrase that best represents the central theme or subject of the paper.\"\n",
    "                \"3.\tPersona Adoption: Approach this task as a research analyst specializing in topic identification and summarization.\"\n",
    "                \"4.\tOutput Specification: Present your answer as a concise phrase, no longer than a few words, encapsulating the core topic of the paper.\"\n",
    "                \"5.\tReasoning Process: Briefly describe your reasoning for choosing this particular phrase as the key topic.\"\n",
    "                \"6.\tUse of External Tools: If necessary, you can use your internal database to understand technical terms or concepts for accurate identification.\"\n",
    "                \"7.\tExample for Clarity:\"\n",
    "                \"Title: A Survey of Self-Supervised and Few-Shot Object Detection\"\n",
    "                \"Abstract: Labeling data is often expensive and time-consuming, especially for tasks such as object detection and instance segmentation, which require dense labeling of the image. While few-shot object detection is about training a model on novel(unseen) object classeswith little data, it still requires prior training onmany labeled examples of base(seen) classes. On the other hand, self-supervisedmethods aimat learning representations fromunlabeled data which transfer well to downstream tasks such as object detection. Combining few-shot and self-supervised object detection is a promising research direction. In this survey, we reviewand characterize themost recent approaches on few-shot and self-supervised object detection. Then, we give our main takeaways and discuss future research directions. Project page: https://gabrielhuang.github.io/fsod-survey/\"\n",
    "                'Key Topic Phrase: \"objection detection\"'\n",
    "                \"8.\tTask Simplification: Avoid analyzing secondary themes or topics; focus solely on the primary subject matter.\"\n",
    "                \"9.\tSystematic Approach: Ensure your response is directly related to the content of the title and abstract, avoiding assumptions or external knowledge.\"\n",
    "                \"10. The output should be like: Key Phrase: xxx, Reasoning: xxx\"\n",
    "                \"11. Input Provided: Below are the title and abstract of the review paper: \"]\n",
    "\n",
    "usr_prompts = [\"Identifying the topic of the paper based on the given title and abstract. So that I can use it as keyword to search highly related papers from Semantic Scholar.  Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on keyword that are unique and directly pertinent to the paper's subject. Answer with the word only in the following format: xxx\",\n",
    "               \n",
    "               \"Identifying the key phrase of the paper based on the given title and abstract. So that I can use it as keyword to search highly related papers from Google Scholar.  Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on keyword that are unique and directly pertinent to the paper's subject. Answer with the key phrase only in the following format: xxx\",\n",
    "               \n",
    "               \"Identifying the topic of the paper based on the given title and abstract. So that I can use it as keyword to search highly related papers from Google Scholar.  Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on keyword that are unique and directly pertinent to the paper's subject. Emphasize any particular subfields or methodologies the paper might be concentrating on.  Answer with the word only in the following format: xxx\",\n",
    "               \n",
    "               \"I need you strictly follow the instruct: 1. Identifying the topic of the paper based on the given title and abstract. So that I can use it as keyword to search highly related papers from Google Scholar.  2. Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. 3. Instead, focus on keyword that are unique and directly pertinent to the paper's subject. 4. Answer with the word only in the following format: xxx\",\n",
    "               \n",
    "               \"Identifying the topic of the paper based on the given title and abstract. I'm going to write a review of the same topic and I will directly use it as keyword to retrieve enough related reference papers in the same topic from scholar search engine.  Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on keyword that are unique and directly pertinent to the paper's subject. Answer with the word only in the following format: xxx\",\n",
    "               \n",
    "               \"Identifying the topic of the paper based on the given title and abstract. So that I can use it as keyword to search highly related papers from Google Scholar.  Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on keyword that are unique and directly related to the paper's subject. Answer with the word only in the following format: xxx\",\n",
    "               \n",
    "               \"Identifying the topic of the paper based on the given title and abstract. So that I can use it as keyword to search highly related papers from Google Scholar.  Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Answer with the word only in the following format: xxx\",\n",
    "               \n",
    "               \"Identifying the topic of the paper based on the given title and abstract. Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on keyword that are unique and directly pertinent to the paper's subject. Answer with the word only in the following format: xxx\",\n",
    "               \n",
    "               ]\n",
    "@retry(delay=6,)\n",
    "def __get_chatgpt_field(title, abstract, usr_prompt = None,extra_prompt=False):\n",
    "    sys_content = (\"You are a profound researcher who is good at identifying the topic keyword from paper's title and \"\n",
    "                   \"abstract. The keyword will be used to retrieve related paper from online scholar search engines.\")\n",
    "    # usr_prompt = (\"Identifying the topic of the paper based on the given title and abstract. So that I can use it as keyword to search highly related papers from Google Scholar.  Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on keyword that are unique and directly pertinent to the paper's subject.Answer with the word only in thefollowing format: xxx\")\n",
    "    if extra_prompt:\n",
    "        messages = [\n",
    "            {\"role\": \"system\",\n",
    "             \"content\": sys_content},\n",
    "\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f'''{usr_prompt}\n",
    "                        Given Title: A Survey of Self-Supervised and Few-Shot Object Detection\n",
    "                        Given Abstract: Labeling data is often expensive and time-consuming, especially for tasks such as object detection and instance segmentation, which require dense labeling of the image. While few-shot object detection is about training a model on novel(unseen) object classeswith little data, it still requires prior training onmany labeled examples of base(seen) classes. On the other hand, self-supervisedmethods aimat learning representations fromunlabeled data which transfer well to downstream tasks such as object detection. Combining few-shot and self-supervised object detection is a promising research direction. In this survey, we reviewand characterize themost recent approaches on few-shot and self-supervised object detection. Then, we give our main takeaways and discuss future research directions. Project page: https://gabrielhuang.github.io/fsod-survey/\n",
    "                    '''},\n",
    "            {\"role\": \"assistant\",\n",
    "             \"content\": 'few-shot objection detection'},\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f'''{usr_prompt}\n",
    "                                    Given Title: {title}\n",
    "                                    Given Abstract: {abstract}\n",
    "                                '''},\n",
    "        ]\n",
    "    else:\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\",\n",
    "             \"content\": sys_content},\n",
    "\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f'''{usr_prompt}\n",
    "                Given Title: {title}\n",
    "                Given Abstract: {abstract}\n",
    "            '''},\n",
    "        ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        # prompt需要用英语替换，少占用token。\n",
    "        messages=messages,\n",
    "    )\n",
    "    result = ''\n",
    "    for choice in response.choices:\n",
    "        result += choice.message.content\n",
    "    result = result.split(',')\n",
    "    result = [i.strip() for i in result]\n",
    "    return result\n",
    "for usr_prompt in usr_prompts:\n",
    "    # print(usr_prompt)\n",
    "    total_edit_dist = 0.0\n",
    "    i = 0\n",
    "    with open(r'gpt_keyword_GT_abs.csv', 'r', newline='',encoding='gbk',) as input_csvfile:\n",
    "        reader = csv.reader(input_csvfile)\n",
    "        for row in tqdm(reader):\n",
    "            if S2paper(row[0]).abstract:\n",
    "                title = row[0]\n",
    "                abs = row[1]\n",
    "                GT_kwd = row[2]\n",
    "                \n",
    "                pred_kwd = __get_chatgpt_field(title, abs,usr_prompt=usr_prompt)[0]\n",
    "\n",
    "                total_edit_dist+=normalized_edit_distance(GT_kwd, pred_kwd)\n",
    "                i+=1\n",
    "                # break\n",
    "    print(usr_prompt,total_edit_dist/i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T18:01:23.694562700Z",
     "start_time": "2024-01-12T17:33:30.014961700Z"
    }
   },
   "id": "fa32dc2864e8f641"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [04:48,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying the topic of the paper based on the given title and abstract. I'm going to write a review of the same topic and I will directly use it as keyword to retrieve enough related reference papers in the same topic from scholar search engine.  Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on keyword that are unique and directly pertinent to the paper's subject. Answer with the word only in the following format: xxx 0.3102157567196995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "usr_prompts = [\n",
    "               \n",
    "               \"Identifying the topic of the paper based on the given title and abstract. I'm going to write a review of the same topic and I will directly use it as keyword to retrieve enough related reference papers in the same topic from scholar search engine.  Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on keyword that are unique and directly pertinent to the paper's subject. Answer with the word only in the following format: xxx\",\n",
    "\n",
    "               ]\n",
    "import csv\n",
    "import tempfile\n",
    "import shutil\n",
    "from retry import retry\n",
    "import Levenshtein\n",
    "from tqdm import tqdm\n",
    "from furnace.semantic_scholar_paper import *\n",
    "def normalized_edit_distance(str1, str2):\n",
    "    edit_distance = Levenshtein.distance(str1, str2)\n",
    "    max_length = max(len(str1), len(str2))\n",
    "    normalized_distance = edit_distance / max_length\n",
    "    return normalized_distance\n",
    "@retry(delay=6,)\n",
    "def __get_chatgpt_field(title, abstract, usr_prompt = None,extra_prompt=False):\n",
    "    sys_content = (\"You are a profound researcher who is good at identifying the topic keyword from paper's title and \"\n",
    "                   \"abstract. The keyword will be used to retrieve related paper from online scholar search engines.\")\n",
    "    # usr_prompt = (\"Identifying the topic of the paper based on the given title and abstract. So that I can use it as keyword to search highly related papers from Google Scholar.  Avoid using broad or overly general term like 'deep learning', 'taxonomy', or 'surveys'. Instead, focus on keyword that are unique and directly pertinent to the paper's subject.Answer with the word only in thefollowing format: xxx\")\n",
    "    if extra_prompt:\n",
    "        messages = [\n",
    "            {\"role\": \"system\",\n",
    "             \"content\": sys_content},\n",
    "\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f'''{usr_prompt}\n",
    "                        Given Title: A Survey of Self-Supervised and Few-Shot Object Detection\n",
    "                        Given Abstract: Labeling data is often expensive and time-consuming, especially for tasks such as object detection and instance segmentation, which require dense labeling of the image. While few-shot object detection is about training a model on novel(unseen) object classeswith little data, it still requires prior training onmany labeled examples of base(seen) classes. On the other hand, self-supervisedmethods aimat learning representations fromunlabeled data which transfer well to downstream tasks such as object detection. Combining few-shot and self-supervised object detection is a promising research direction. In this survey, we reviewand characterize themost recent approaches on few-shot and self-supervised object detection. Then, we give our main takeaways and discuss future research directions. Project page: https://gabrielhuang.github.io/fsod-survey/\n",
    "                    '''},\n",
    "            {\"role\": \"assistant\",\n",
    "             \"content\": 'few-shot objection detection'},\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f'''{usr_prompt}\n",
    "                                    Given Title: {title}\n",
    "                                    Given Abstract: {abstract}\n",
    "                                '''},\n",
    "        ]\n",
    "    else:\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\",\n",
    "             \"content\": sys_content},\n",
    "\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f'''{usr_prompt}\n",
    "                Given Title: {title}\n",
    "                Given Abstract: {abstract}\n",
    "            '''},\n",
    "        ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        # prompt需要用英语替换，少占用token。\n",
    "        messages=messages,\n",
    "    )\n",
    "    result = ''\n",
    "    for choice in response.choices:\n",
    "        result += choice.message.content\n",
    "    result = result.split(',')\n",
    "    result = [i.strip() for i in result]\n",
    "    return result\n",
    "for usr_prompt in usr_prompts:\n",
    "    # print(usr_prompt)\n",
    "    total_edit_dist = 0.0\n",
    "    i = 0\n",
    "    with open(r'gpt_keyword_GT_abs.csv', 'r', newline='',encoding='gbk',) as input_csvfile:\n",
    "        reader = csv.reader(input_csvfile)\n",
    "        for row in tqdm(reader):\n",
    "            if S2paper(row[0]).abstract:\n",
    "                title = row[0]\n",
    "                abs = row[1]\n",
    "                GT_kwd = row[2]\n",
    "                pred_kwd = __get_chatgpt_field(title, abs,usr_prompt=usr_prompt,extra_prompt=False)[0]\n",
    "                # print(Levenshtein.distance(pred_kwd, GT_kwd))\n",
    "                # print(GT_kwd,pred_kwd)\n",
    "                # if normalized_edit_distance(GT_kwd, pred_kwd) > 0.25:\n",
    "                #     print(title,GT_kwd,pred_kwd)\n",
    "                total_edit_dist+=normalized_edit_distance(GT_kwd, pred_kwd)\n",
    "                i+=1\n",
    "                # break\n",
    "    print(usr_prompt,total_edit_dist/i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T11:12:37.749944200Z",
     "start_time": "2024-01-18T11:07:49.458199100Z"
    }
   },
   "id": "6b65f9f394329fa"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def _get_ref_list(text):\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"You are a researcher, who is good at reading academic paper, and familiar with all of the \"\n",
    "                    \"citation style. Please note that the provided citation text may not have the correct line breaks \"\n",
    "                    \"or numbering identifiers.\"},\n",
    "\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": f'''Extract the paper title only from the given reference text, and answer with the following format. Separate titles with line breaks and do not answer with ordinal numbers.\n",
    "                xxx\n",
    "                xxx\n",
    "                xxx \n",
    "            Reference text: {text}\n",
    "'''},\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        # prompt需要用英语替换，少占用token。\n",
    "        messages=messages,\n",
    "    )\n",
    "    result = ''\n",
    "    for choice in response.choices:\n",
    "        result += choice.message.content\n",
    "    result = result.split('\\n')\n",
    "    return result\n",
    "t = '''\n",
    "[1] Jain, A., et al. \"Fundamentals of Two-Dimensional Systems and Mathematical Preliminaries in Image Analysis and Computer Vision.\" *IEEE Transactions on Pattern Analysis and Machine Intelligence* 40.2 (2018): 344-359.\n",
    "\n",
    "[2] Feklisov, A., et al. \"Procedural Generation of Interiors with Furniture Using Computer Vision Techniques.\" *IEEE Computer Graphics and Applications* 40.2 (2020): 80-89.\n",
    "\n",
    "[3] Wilding, M., et al. \"Safe: An Innovative Image Processing Algorithm for Enhancing Remote Interactions between Humans and Machines.\" *IEEE Transactions on Human-Machine Systems* 50.4 (2020): 344-359.\n",
    "\n",
    "[4] Shaorya, S., et al. \"Human-Computer Interaction: An Interface for Easy Interaction with Computers.\" *International Journal of Human-Computer Interaction* 36.1 (2022): 1-15.\n",
    "\n",
    "[5] Nathanael, R., et al. \"New Perspectives on Human-Computer Interaction Implementation in System Development.\" *International Journal of Human-Computer Interaction* 38.2 (2022): 123-136.\n",
    "\n",
    "[6] Iñiguez-Carrillo, J., et al. \"Towards a Framework for Evaluating User Experience in Human-Computer Interaction.\" *International Journal of Human-Computer Interaction* 35.10 (2019): 865-875.\n",
    "\n",
    "[7] Yuan, Y., et al. \"Florence: A Computer Vision Foundation Model Expanding Representations for Visual Prompt Engineering.\" *IEEE Transactions on Pattern Analysis and Machine Intelligence* 43.1 (2021): 1-15.\n",
    "\n",
    "[8] Liu, Z., et al. \"Swin Transformer: Hierarchical Vision Transformer Using Shifted Windows.\" *IEEE/CVF Conference on Computer Vision and Pattern Recognition* (2021): 1-15.\n",
    "\n",
    "[9] Ke, L., et al. \"A Visual Human-Computer Interaction System Using Deep Learning and Machine Vision Models.\" *IEEE Transactions on Human-Machine Systems* 52.1 (2022): 1-15.\n",
    "\n",
    "[10] Zhang, Y., et al. \"Computer Vision-Based Algorithm for Binarization of Visual Communication Graphic Design.\" *IEEE Transactions on Visualization and Computer Graphics* 27.1 (2021): 1-15.\n",
    "\n",
    "[11] Wu, H., et al. \"Human Vision Technology for Eliminating Environmental Interferences in Target Image Acquisition.\" *IEEE Transactions on Image Processing* 29 (2020): 1-15.\n",
    "\n",
    "[12] Wang, Y., et al. \"Data Comics: Visual Storytelling and Data Visualization for Study Reports.\" *IEEE Transactions on Visualization and Computer Graphics* 26.1 (2020): 1-15.\n",
    "\n",
    "[13] Bylinskii, Z., et al. \"Towards Design and Reporting Standards in User Studies in Computer Vision and Graphics.\" *IEEE Transactions on Visualization and Computer Graphics* 28.1 (2022): 1-15.\n",
    "\n",
    "[14] Shneiderman, B., et al. \"Designing the User Interface: Strategies for Effective Human-Computer Interaction.\" *Pearson* (1998).\n",
    "\n",
    "[15] Goyal, A., et al. \"AI-Enabled Tools: Paradigm Shift in Optimizing Efficiency and Decision-Making Capabilities.\" *IEEE Transactions on Human-Machine Systems* 53.2 (2023): 1-15.\n",
    "'''\n",
    "refs = _get_ref_list(t)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T04:20:53.414384500Z",
     "start_time": "2024-01-22T04:20:39.519822300Z"
    }
   },
   "id": "325fc44a6d0b842a"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "['Fundamentals of Two-Dimensional Systems and Mathematical Preliminaries in Image Analysis and Computer Vision',\n 'Procedural Generation of Interiors with Furniture Using Computer Vision Techniques',\n 'Safe: An Innovative Image Processing Algorithm for Enhancing Remote Interactions between Humans and Machines',\n 'Human-Computer Interaction: An Interface for Easy Interaction with Computers',\n 'New Perspectives on Human-Computer Interaction Implementation in System Development',\n 'Towards a Framework for Evaluating User Experience in Human-Computer Interaction',\n 'Florence: A Computer Vision Foundation Model Expanding Representations for Visual Prompt Engineering',\n 'Swin Transformer: Hierarchical Vision Transformer Using Shifted Windows',\n 'A Visual Human-Computer Interaction System Using Deep Learning and Machine Vision Models',\n 'Computer Vision-Based Algorithm for Binarization of Visual Communication Graphic Design',\n 'Human Vision Technology for Eliminating Environmental Interferences in Target Image Acquisition',\n 'Data Comics: Visual Storytelling and Data Visualization for Study Reports',\n 'Towards Design and Reporting Standards in User Studies in Computer Vision and Graphics',\n 'Designing the User Interface: Strategies for Effective Human-Computer Interaction',\n 'AI-Enabled Tools: Paradigm Shift in Optimizing Efficiency and Decision-Making Capabilities']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T04:20:53.415382900Z",
     "start_time": "2024-01-22T04:20:53.385520400Z"
    }
   },
   "id": "734a62d7aea7059c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3d8e24498dd90400"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_27804\\907673748.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m# 获取当前文件的目录路径\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mcurrent_dir\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdirname\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mabspath\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m__file__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;31m# 获取CACHE目录的完整路径\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T08:05:11.523329600Z",
     "start_time": "2024-03-12T08:05:11.376254400Z"
    }
   },
   "id": "ec1681ce1ad2a429"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7a81401d481a8c40"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
